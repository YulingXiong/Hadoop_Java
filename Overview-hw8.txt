{\rtf1\ansi\ansicpg1252\cocoartf1344\cocoasubrtf720
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 ArialMT;\f2\fnil\fcharset0 LucidaGrande;
}
{\colortbl;\red255\green255\blue255;\red26\green26\blue26;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid1\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\margl1440\margr1440\vieww18940\viewh6680\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\b\fs28 \cf0 Overview
\b0\fs24 \
\

\b TagUnion.java
\b0 \
The key thing is the data structure chosen in the Reduced phase. \
In 
\b Map
\b0  phase: (K1, V1) -> list
\b (K2, V2),
\b0   the emitted list is (K2=url, V2=tag). \
Mapper<LongWritable, Text, 
\b Text, Text
\b0 >\
\
In 
\b Reduce
\b0  phase: 
\b (K2, list(V2))
\b0  -> list(K3, V3), for each key=url, the emitted value is stored in a 
\b HashSet<String>
\b0  to store all the unique tags linked with this url. Then string value in this HashSet is concatenated into a long String separated by comma, which is further transformed into Text format as the output.\

\b Reducer
\b0 <
\b Text, Text
\b0 , Text, Text>\
\
AliceXiong$jar cf HW8.jar cscie55/hw8/TagUnion*.class cscie55/hw8/UrlCount*.class cscie55/hw8/Link*.class cscie55/hw8/files.1
\f1\fs26 \cf2 \expnd0\expndtw0\kerning0
\

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 AliceXiong$
\f1\fs26 \cf2 \expnd0\expndtw0\kerning0
hadoop jar HW8.jar cscie55.hw8.TagUnion -fs file:/// -jt local cscie55/hw8/files.1 cscie55/hw8/output1\

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\

\b UrlCount.java
\b0 \
It is very similar to WordCount, but it has some minor difference below:\
We need to parse the 
\b startDate
\b0 =08-09-2009 and 
\b endDate
\b0 =09-09-2009 these two more arguments in the cmd. So we call 
\b con.set
\b0 () before launching the job. \
	Configuration conf = new Configuration();\
	
\b conf.set
\b0 ("startDate", args[2]);\
	
\b conf.set
\b0 ("endDate", args[3]);\
	Job job = new Job(conf);\
\
Then we need to get the parameters implemented in the Mapper class. Then we use 
\b context
\b0  to pass the parameters into map function. \
	Configuration config = 
\b context
\b0 .getConfiguration();\
	String startDateString = 
\b config.get
\b0 ("startDate");\
  	String endDateString = 
\b config.get
\b0 ("endDate");\
The DateString is further transferred into unix timestamp later, which is the selection criteria for url count. \
\
The only strange issue I meet in problem2 is that, I can run in on the HDFS server but not locally. The following cmd showed how to run in on the server. And then I copy the Output file from HDFS server into my local folders \'93AliceXiong$
\f1\fs26 \cf2 \expnd0\expndtw0\kerning0
hadoop fs -
\b \expnd0\expndtw0\kerning0
get
\b0 \expnd0\expndtw0\kerning0
 hdfs://localhost/user/AliceXiong/
\b \expnd0\expndtw0\kerning0
output4
\b0 \expnd0\expndtw0\kerning0
 cscie55/hw8
\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \'94\
\
\
\pard\pardeftab720

\f1\fs26 \cf2 \expnd0\expndtw0\kerning0
hadoop fs -
\b \expnd0\expndtw0\kerning0
copyFromLocal
\b0 \expnd0\expndtw0\kerning0
 cscie55/hw8/files.1 input2\
hadoop fs -ls input2\
hadoop jar HW8.jar cscie55.hw8.UrlCount -fs file:/// -jt local input2 output4 08-11-2009 09-11-2009\
\

\b \expnd0\expndtw0\kerning0
hadoop fs -ls output4\
\pard\tx220\tx720\pardeftab720\li720\fi-720
\ls1\ilvl0
\b0 \cf2 \kerning1\expnd0\expndtw0 {\listtext	
\f2 \uc0\u8259 
\f1 	}\expnd0\expndtw0\kerning0
Found 2 items\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa256
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	
\f2 \uc0\u8259 
\f1 	}\expnd0\expndtw0\kerning0
-rw-r--r-- \'a0 1 AliceXiong supergroup\'a0 \'a0 \'a0 \'a0 \'a0 0 2016-05-14 18:09 output4/_SUCCESS\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	
\f2 \uc0\u8259 
\f1 	}\expnd0\expndtw0\kerning0
-rw-r--r-- \'a0 1 AliceXiong supergroup\'a0 \'a0 \'a0 12930 2016-05-14 18:09 output4/part-r-00000\
\pard\pardeftab720
\cf2 \expnd0\expndtw0\kerning0
hadoop fs -tail -f output4/part-r-00000\
hadoop fs -get hdfs://localhost/user/AliceXiong/output4 cscie55/hw8\
\pard\pardeftab720\sa256
\cf2 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \
}